{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f519c8",
   "metadata": {
    "direction": "rtl",
    "id": "46f519c8"
   },
   "source": [
    "## سدره ميرخان"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efe140",
   "metadata": {
    "id": "e7efe140"
   },
   "source": [
    "Prepare libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Ie-c0nE4Z9p7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ie-c0nE4Z9p7",
    "outputId": "024b5a21-3d3e-482f-fd81-d4eeee266bc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting Arabic-Stopwords\n",
      "  Downloading Arabic_Stopwords-0.3-py3-none-any.whl (353 kB)\n",
      "\u001b[K     |████████████████████████████████| 353 kB 34.1 MB/s \n",
      "\u001b[?25hCollecting pyarabic>=0.6.2\n",
      "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 65.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic>=0.6.2->Arabic-Stopwords) (1.15.0)\n",
      "Installing collected packages: pyarabic, Arabic-Stopwords\n",
      "Successfully installed Arabic-Stopwords-0.3 pyarabic-0.6.15\n"
     ]
    }
   ],
   "source": [
    "!pip install Arabic-Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af6058ed",
   "metadata": {
    "id": "af6058ed"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# here put every import you need e.g.\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import arabicstopwords.arabicstopwords as stp\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras import layers,losses\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.svm import SVC  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229df102",
   "metadata": {
    "id": "229df102"
   },
   "source": [
    "Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5504e7ee",
   "metadata": {
    "id": "5504e7ee"
   },
   "outputs": [],
   "source": [
    "# !wget 'https://drive.google.com/uc?export=download&id=1121dzWdV2ZIrQSSSLs0N4P5b3qRwg428' -O 'final_data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530e1bac",
   "metadata": {
    "id": "530e1bac"
   },
   "outputs": [],
   "source": [
    "# !unzip final_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec48c7b",
   "metadata": {
    "id": "4ec48c7b"
   },
   "source": [
    "Prapere The Comparison Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0428b0f2",
   "metadata": {
    "id": "0428b0f2"
   },
   "outputs": [],
   "source": [
    "model_comparison_table = {}\n",
    "\n",
    "model_comparison_table['question_step_number'] = []\n",
    "model_comparison_table['model_name'] = []\n",
    "model_comparison_table['parameters'] = []\n",
    "model_comparison_table['preprocessing_methods'] = []\n",
    "model_comparison_table['accuracy'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3400638b",
   "metadata": {
    "id": "3400638b"
   },
   "source": [
    "# Question [1]: Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8E7xa9XLPW8t",
   "metadata": {
    "id": "8E7xa9XLPW8t"
   },
   "source": [
    "شرح ما يقوم به الكود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf32b148",
   "metadata": {
    "id": "bf32b148"
   },
   "outputs": [],
   "source": [
    "def drop_duplicate_empty(data):\n",
    "    data.drop_duplicates(inplace = True,subset = 'text')\n",
    "#     print(\"The total number of samples is after removing duplicates :\",data.shape[0])\n",
    "    data['label'].replace('  ', np.nan, inplace=True)\n",
    "    data['text'].replace('  ', np.nan, inplace=True)\n",
    "    data =data.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41a9612",
   "metadata": {
    "id": "d41a9612"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def load_data(file):\n",
    "    data = pd.read_csv(file)\n",
    "    print(\"The total number of samples is :\",data.shape[0])\n",
    "#     print(data.head())\n",
    "#     print()\n",
    "    data = drop_duplicate_empty(data)\n",
    "    print(\"The total number of samples is after removing empty and duplicates cells:\",data.shape[0])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fffa23",
   "metadata": {
    "id": "12fffa23"
   },
   "outputs": [],
   "source": [
    "positivePattern = r\"(p|P)(.)*\"\n",
    "irreleventPattern = r\"(i|I)(.)*\"\n",
    "neutralPattern = r\"(.)*(l|L)$\"\n",
    "labels = ['positive','negative','irrelevant','neutral']\n",
    "def uniform_labels(x):\n",
    "    x = str(x)\n",
    "    if re.match(positivePattern,x):\n",
    "        return re.sub(positivePattern,labels[0],x)\n",
    "    elif re.match(irreleventPattern,x):\n",
    "        return re.sub(irreleventPattern,labels[2],x)\n",
    "    elif re.search(neutralPattern,x):\n",
    "        return re.sub(neutralPattern,labels[3],x)\n",
    "    return labels[1]\n",
    " \n",
    "def uniform_dataframe_labels(data):\n",
    "    data['label']= data['label'].apply(uniform_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8cc963",
   "metadata": {
    "id": "4b8cc963"
   },
   "outputs": [],
   "source": [
    "def get_tweets_targets_columns(data):\n",
    "    x = data['text'] \n",
    "    y = data['label']\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e120ff1",
   "metadata": {
    "id": "5e120ff1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_postive_negative_data(data):\n",
    "    df = data.copy()\n",
    "    df =  df[df.label.isin([labels[0],labels[1]])]\n",
    "    df['label_num'] = df.label.apply(lambda l:1 if l ==labels[0] else 0)\n",
    "    # train_data_01 = train_data.query(f'label == {labels[0]} | label == {labels[1]}')\n",
    "    print(\"the num of positive and negative in train is:\",df.shape[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785d8ea6",
   "metadata": {
    "id": "785d8ea6"
   },
   "outputs": [],
   "source": [
    "#     df[\"sentiments\"].loc[df[\"sentiments\"]==\"positif\"]=1.0\n",
    "#     df[\"sentiments\"].loc[df[\"sentiments\"]==\"negatif\"]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ded98af2",
   "metadata": {
    "id": "ded98af2"
   },
   "outputs": [],
   "source": [
    "def get_data(file):\n",
    "    data =load_data(file)\n",
    "    uniform_dataframe_labels(data)\n",
    "    data_01 = get_postive_negative_data(data)\n",
    "#     data_x,data_y = get_tweets_targets_columns(data_01)\n",
    "    return data,data_01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10274c46",
   "metadata": {
    "id": "10274c46"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12135926",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12135926",
    "outputId": "b1bc2536-eefd-4a5d-a71b-9ef7917fa4e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is : 33924\n",
      "The total number of samples is after removing empty and duplicates cells: 24729\n",
      "the num of positive and negative in train is: 10476\n"
     ]
    }
   ],
   "source": [
    "train_data,train_data_01 =get_data('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36455a06",
   "metadata": {
    "id": "36455a06"
   },
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e497c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51e497c2",
    "outputId": "5202f3dd-a08d-45ed-d00b-8aa44768fae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is : 7269\n",
      "The total number of samples is after removing empty and duplicates cells: 6723\n",
      "the num of positive and negative in train is: 2873\n"
     ]
    }
   ],
   "source": [
    "valid_data,valid_data_01 =get_data('valid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9db42f",
   "metadata": {
    "id": "0a9db42f"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d422edb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d422edb",
    "outputId": "8a11ca93-096c-4bd0-a3c3-82e802a4ca1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is : 7270\n",
      "The total number of samples is after removing empty and duplicates cells: 6714\n",
      "the num of positive and negative in train is: 2913\n"
     ]
    }
   ],
   "source": [
    "test_data,test_data_01 =get_data('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aNNrMjaaQanf",
   "metadata": {
    "id": "aNNrMjaaQanf"
   },
   "outputs": [],
   "source": [
    "# حال اختبار في حال وجودها"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9NfyVxZQXF7",
   "metadata": {
    "id": "d9NfyVxZQXF7"
   },
   "source": [
    "بعد كل خطوة ستكتب إجابة السؤال في حال وجوده أو ملاحظاتك أيضاً في حال وجودها."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f22713d",
   "metadata": {
    "id": "2f22713d"
   },
   "source": [
    "# Question [2]: Baseline: Bag of Words with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef90d1",
   "metadata": {
    "direction": "rtl",
    "id": "03ef90d1"
   },
   "source": [
    "<font size=\"4\">\n",
    " تمّ استخدام CountVectorizer لتحويل النص لـdata رقمية عن طريق تكرار الكلمة بالجملة، فنقوم بعمليتي fit و transform على داتا التدريب، , transform على داتا الاختبار، ومن ثم تم استخدام LogisticRegression لتنبؤ بالخرج ويلي هو 0 أو 1 ومن ثم اختبرنا الدقة "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8c64b",
   "metadata": {
    "id": "c1b8c64b"
   },
   "outputs": [],
   "source": [
    "# do code\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_data_01.text)\n",
    "\n",
    "X_train = vectorizer.transform(train_data_01.text)\n",
    "X_valid = vectorizer.transform(valid_data_01.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SexYXq1-P0Y0",
   "metadata": {
    "id": "SexYXq1-P0Y0",
    "outputId": "62616f87-b182-472d-e2c7-06d23c1aecf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8064740689175078\n"
     ]
    }
   ],
   "source": [
    "# test your model\n",
    "classifier = LogisticRegression(max_iter =  200)\n",
    "classifier.fit(X_train, train_data_01.label)\n",
    "accuracy = classifier.score(X_valid, valid_data_01.label)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "_iqs3mUtB8UV",
   "metadata": {
    "id": "_iqs3mUtB8UV"
   },
   "outputs": [],
   "source": [
    "model_comparison_table['question_step_number'].append(\"2\")\n",
    "model_comparison_table['model_name'].append(\"baseline logistic regression with bag of words\")\n",
    "model_comparison_table['parameters'].append(\"default\")\n",
    "model_comparison_table['preprocessing_methods'].append(\"none\")\n",
    "model_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFmJ2HWqRNZa",
   "metadata": {
    "id": "oFmJ2HWqRNZa"
   },
   "source": [
    "# Question [3]: Text Cleaning and Normalization on Bag of Words with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyzKeB0QC8sY",
   "metadata": {
    "id": "lyzKeB0QC8sY"
   },
   "source": [
    "Prapere The Comparison Dictionary for this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87mEw9pC8sZ",
   "metadata": {
    "id": "a87mEw9pC8sZ"
   },
   "outputs": [],
   "source": [
    "bag_logistic_comparison_table = {}\n",
    "\n",
    "bag_logistic_comparison_table['question_step_number'] = []\n",
    "bag_logistic_comparison_table['preprocessing_methods'] = []\n",
    "bag_logistic_comparison_table['accuracy'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54585de3",
   "metadata": {
    "id": "54585de3"
   },
   "outputs": [],
   "source": [
    "def delete_mentions(tweet):\n",
    "    tweet = re.sub(r\"@\\S+\", '', tweet) #delete mentions\n",
    "    return tweet\n",
    "\n",
    "def delete_url(tweet):\n",
    "    tweet = re.sub(r'https?\\S+', '', tweet) #delete url\n",
    "    return tweet\n",
    "\n",
    "def delete_hashtag(tweet):\n",
    "    tweet = re.sub(r'#\\S+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "def delete_repeated_letter(tweet):\n",
    "    pattern = r\"([^\\d٠-٩])\\1{2,}\"\n",
    "    tweet = re.sub(pattern,r\"\\1\",tweet)\n",
    "    return tweet\n",
    "\n",
    "diff= ord('٠')-ord('0')\n",
    "def numbers_uniform(tweet):\n",
    "    tweet = re.sub(r\"([٠-٩])\", lambda match: chr(ord(match.group(0))-diff),tweet)\n",
    "    return tweet\n",
    "\n",
    "num_pattern = r\"[\\d٠-٩]+\"\n",
    "def replace_numbers(tweet):\n",
    "    output =  re.sub(num_pattern,\"*\",tweet)\n",
    "    return output\n",
    "\n",
    "def del_numbers(tweet):\n",
    "    output =  re.sub(num_pattern,\"\",tweet)\n",
    "    return output\n",
    "\n",
    "pnc_pattern = r\"[\\.!$%&()+?#_,<>/-:;=\\\\،^`{|}~\\*؟]+\"\n",
    "def replace_symbols(tweet):\n",
    "    output =  re.sub(pnc_pattern,\"\",tweet)\n",
    "    return output\n",
    "\n",
    "emj_pattern =r\"[^\\p{L}\\p{M}\\p{N}\\p{P}\\p{Z}\\p{Cf}\\p{Cs}\\s]\"\n",
    "def delete_emojies(tweet):\n",
    "    output =  re.sub(emj_pattern,\"\",tweet)\n",
    "    return output\n",
    "\n",
    "def delete_all_not_arabic(tweet):\n",
    "    pattern = r\"([\\u0600-\\u06FF]+|[^\\p{L}\\p{M}\\p{N}\\p{P}\\p{Z}\\p{Cf}\\p{Cs}\\s]+|[@!$%&()+?,./:;=\\\\،^`{|}~\\*]+|[\\d\\.٠-٩]+|#\\S+)|(\\S*)\"\n",
    "    tweet = re.sub(pattern, lambda match: match.groups()[0],tweet) \n",
    "    return tweet\n",
    "\n",
    "def del_stop_words(text):\n",
    "    return \" \".join([w for w in text.split() if not stp.is_stop(w)])\n",
    "\n",
    "st = ISRIStemmer()\n",
    "def lemmatization(text):\n",
    "    return \" \".join([st.stem(w) for w in text.split()])\n",
    "\n",
    "def uniform_hamza(text):\n",
    "    output = re.sub(r\"ئ|ؤ\",\"ء\",text)\n",
    "    return output\n",
    "\n",
    "def uniform_alef(text):\n",
    "    output = re.sub(r\"إ|أ|آ\",\"ا\",text)\n",
    "    return output\n",
    "\n",
    "def del_tatweel(text):\n",
    "    output = re.sub( r\"ـ\",\"\",text)\n",
    "    return output\n",
    "\n",
    "def del_tashkil(text):\n",
    "    tashkil_pattern = r\"[\\u064B-\\u0652]\"\n",
    "    output = re.sub(tashkil_pattern ,\"\",text)\n",
    "    return output\n",
    "\n",
    "def del_space(text):\n",
    "    output = re.sub(r\"(\\s)\\1+\",r\"\\1\",text)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c255b5c",
   "metadata": {
    "id": "6c255b5c"
   },
   "outputs": [],
   "source": [
    "clean= {  \"remove_url\" : \"3.1\",\n",
    "                \"remove_mentions\" : \"3.1\",\n",
    "                \"remove_hashtags\" : \"3.2\",\n",
    "                \"remove_repeated\":\"3.3\",\n",
    "                \"uniform_nums\" : \"3.4.1\",\n",
    "                \"replace_nums\" :\"3.4.2\",\n",
    "                \"remove_nums\":\"3.4.3\",\n",
    "                \"remove_all_non_arabic\":\"3.5.1\",\n",
    "                \"remove_punctuation\": \"3.5.2\",\n",
    "                \"remove_emojies\":\"3.5.3\",\n",
    "                \"remove_stop_words\":\"3.6\", \n",
    "                \"lemmatization\":\"3.7\",\n",
    "                \"uniform_hamza\" : \"3.8.1\",\n",
    "                \"uniform_alef\" : \"3.8.2\",\n",
    "                \"tatweel\" : \"3.8.3\",\n",
    "                \"tashkil\" : \"3.8.4\",\n",
    "                \"remove_space\" :\"3.9\"\n",
    "             }\n",
    "\n",
    "clean_list = [ \"remove_url\" ,\"remove_mentions\" ,\"remove_hashtags\",\"remove_repeated\",\"uniform_nums\",\"replace_nums\",\n",
    "                \"remove_nums\",\"remove_all_non_arabic\",\"remove_punctuation\",\"remove_emojies\",\n",
    "                \"remove_stop_words\", \"lemmatization\",\"uniform_hamza\",\"uniform_alef\" ,\"tatweel\",\"tashkil\" ,\n",
    "              \"remove_space\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6a1a01e",
   "metadata": {
    "id": "f6a1a01e"
   },
   "outputs": [],
   "source": [
    "def preprocess(tweet,clean_list= clean_list):\n",
    "  \n",
    "    if \"remove_url\" in clean_list:\n",
    "        tweet = delete_url(tweet)\n",
    "#         print(clean[\"remove_url\"])\n",
    "    if \"remove_mentions\" in clean_list:\n",
    "        tweet =delete_mentions(tweet)\n",
    "#         print(clean[\"remove_mentions\"])\n",
    "    if \"remove_hashtags\" in clean_list:\n",
    "        tweet =delete_hashtag(tweet)\n",
    "#         print(clean[\"remove_hashtags\"])\n",
    "    if \"remove_repeated\" in clean_list:\n",
    "        tweet =delete_repeated_letter(tweet)\n",
    "#         print(clean[\"remove_repeated\"])\n",
    "        \n",
    "    if \"uniform_nums\" in clean_list:\n",
    "        tweet = numbers_uniform(tweet)\n",
    "#         print(clean[\"uniform_nums\"])\n",
    "    if \"replace_nums\" in clean_list:\n",
    "        tweet =  replace_numbers(tweet)\n",
    "#         print(clean[\"replace_nums\"])\n",
    "    if \"remove_nums\" in clean_list:\n",
    "        tweet =del_numbers(tweet)\n",
    "#         print(clean[\"remove_nums\"])\n",
    "    if \"remove_punctuation\" in clean_list:\n",
    "        tweet = replace_symbols(tweet)\n",
    "#         print(clean[\"remove_punctuation\"])\n",
    "    if \"remove_emojies\" in clean_list:\n",
    "        tweet = delete_emojies(tweet)\n",
    "#         print(clean[\"remove_emojies\"])\n",
    "    if \"remove_all_non_arabic\" in clean_list:\n",
    "        tweet = delete_all_not_arabic(tweet)\n",
    "#         print(clean[\"remove_all_non_arabic\"])\n",
    "        \n",
    "    if  \"uniform_hamza\" in clean_list:\n",
    "        tweet = uniform_hamza(tweet)\n",
    "#         print(clean[\"uniform_hamza\"])\n",
    "    if \"uniform_alef\" in clean_list:\n",
    "        tweet =  uniform_alef(tweet)\n",
    "#         print(clean[\"uniform_alef\"])\n",
    "    if \"tatweel\" in clean_list:\n",
    "        tweet = del_tatweel(tweet)\n",
    "#         print(clean[\"tatweel\"])\n",
    "    if \"tashkil\" in clean_list:\n",
    "        tweet = del_tashkil(tweet)\n",
    "#         print(clean[\"tashkil\"])\n",
    "    if \"remove_space\" in clean_list:\n",
    "        tweet = del_space(tweet)\n",
    "#         print(clean[\"remove_space\"])\n",
    "        \n",
    "    if \"remove_stop_words\" in clean_list:\n",
    "        tweet = del_stop_words(tweet)\n",
    "#         print(clean[\"remove_stop_words\"])\n",
    "    if \"lemmatization\" in clean_list:\n",
    "        tweet = lemmatization(tweet)\n",
    "#         print(clean[\"lemmatization\"])\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38a1c285",
   "metadata": {
    "id": "38a1c285"
   },
   "outputs": [],
   "source": [
    "def store_results(clean_list,accuracy):\n",
    "    preprocessing_methods = \"\"\n",
    "    question_step_number= \"\"\n",
    "    preprocessing_methods = \" + \".join(clean_list)\n",
    "    question_step_number= clean[clean_list[-1]]\n",
    "    \n",
    "    bag_logistic_comparison_table['question_step_number'].append(question_step_number)\n",
    "    bag_logistic_comparison_table['preprocessing_methods'].append(preprocessing_methods)\n",
    "    bag_logistic_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "081bef71",
   "metadata": {
    "id": "081bef71"
   },
   "outputs": [],
   "source": [
    "def drop_duplicate_empty_for_clean_data(data,c=\"cleaned\"):\n",
    "    data.drop_duplicates(inplace = True,subset =c )\n",
    "    data[c].replace('  ', np.nan, inplace=True)\n",
    "    data =data[data[c].notna()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41272eb5",
   "metadata": {
    "direction": "rtl",
    "id": "41272eb5"
   },
   "source": [
    "<font size=\"4\">\n",
    "يأخذ التابع عمليات التنظيف التي سيقوم بها وينفذها على داتا التدريب وداتا الاختبار ونقوم بعمليتي fit و transform على داتا التدريب، , transform على داتا الاختبار ومن ثم نختبر دقة الـlogistic regression ونخزنها بdictionary المقارنة، وسنستدعي هذا التابع من أجل كل عملية تنظيف بهذا القسم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647ce33",
   "metadata": {
    "id": "9647ce33"
   },
   "outputs": [],
   "source": [
    "\n",
    "def classify_on_cleaned_data(clean):\n",
    "    # do code\n",
    "#     train_data_01_x_cleaned =list(map(lambda tweet: preprocess(tweet, clean),train_data_01_x))\n",
    "#     valid_data_01_x_cleaned =list(map(lambda tweet: preprocess(tweet, clean),valid_data_01_x))\n",
    "    train = train_data_01.copy()\n",
    "    valid = valid_data_01.copy()\n",
    "    train[\"cleaned\"] =train.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "    valid[\"cleaned\"] =valid.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "\n",
    "    train = drop_duplicate_empty_for_clean_data(train)\n",
    "    valid = drop_duplicate_empty_for_clean_data(valid)\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    classifier = LogisticRegression(max_iter =  200)\n",
    "    \n",
    "    X_train = vectorizer.fit_transform(train.cleaned)\n",
    "    X_valid = vectorizer.transform(valid.cleaned)\n",
    "\n",
    "    # test your model\n",
    "    classifier.fit(X_train, train.label_num)\n",
    "    accuracy = classifier.score(X_valid, valid.label_num)\n",
    "    \n",
    "    store_results(clean,accuracy)\n",
    "#     print(train.cleaned.values[:5])\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cwaCNfS9RNZc",
   "metadata": {
    "id": "cwaCNfS9RNZc"
   },
   "source": [
    "## [3.1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TCMARMvlCs9l",
   "metadata": {
    "id": "TCMARMvlCs9l",
    "outputId": "7b3b7330-ce04-4c07-cb2a-3f794a7f56e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8044614848379226\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data( [\"remove_url\" ,\"remove_mentions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MbJeF_CxRNZd",
   "metadata": {
    "id": "MbJeF_CxRNZd"
   },
   "source": [
    "## [3.2] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TywIVZd_dVjq",
   "metadata": {
    "id": "TywIVZd_dVjq"
   },
   "source": [
    "<font size=\"4\">\n",
    "إنّ حذف الهاشتاغات أنقص الدقة قليلا ولذلك لأنها قد تحوي معلومات مهمة \n",
    "أتوقع أن إبقاء هذه الـهاشتاغات سيتعطي دقة جيدة في تصنيف بيانات جديدة\n",
    "أخذت في فترة زمنية مختلفة عن الفترة التي تم جمع البيانات فيها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X6yszO6ODdQ8",
   "metadata": {
    "id": "X6yszO6ODdQ8",
    "outputId": "14de36de-fe98-463a-b6ae-0cdeb0d72abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.801811215604319\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"remove_hashtags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GY-HhD2YRNZe",
   "metadata": {
    "id": "GY-HhD2YRNZe"
   },
   "source": [
    "## [3.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l-5TSuHWRNZe",
   "metadata": {
    "id": "l-5TSuHWRNZe",
    "outputId": "9acbe08f-a2bf-4420-f552-0c5d7c937c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8054298642533937\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"remove_repeated\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KV9D86kbRNZe",
   "metadata": {
    "id": "KV9D86kbRNZe"
   },
   "source": [
    "## [3.4] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fM_FPldSCxp",
   "metadata": {
    "id": "3fM_FPldSCxp"
   },
   "source": [
    "### [3.4.1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ohGu5R14RNZe",
   "metadata": {
    "id": "ohGu5R14RNZe",
    "outputId": "fea77dae-1dbf-48df-b461-5de3abdab8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8064740689175078\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"uniform_nums\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N2z1KmQXSAFs",
   "metadata": {
    "id": "N2z1KmQXSAFs"
   },
   "source": [
    "### [3.4.2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fmOXIMWoSAFt",
   "metadata": {
    "id": "fmOXIMWoSAFt",
    "outputId": "324d5736-eaff-4294-a0bc-8d15d3c4c44d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8085624782457361\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fCBHc2y6SAL5",
   "metadata": {
    "id": "fCBHc2y6SAL5"
   },
   "source": [
    "### [3.4.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QJX_PtSzSAL6",
   "metadata": {
    "id": "QJX_PtSzSAL6",
    "outputId": "9de277f7-78fa-45f3-f53a-aca226f4f97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8050817960320222\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"remove_nums\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P1aLjPbzRNZe",
   "metadata": {
    "id": "P1aLjPbzRNZe"
   },
   "source": [
    "## [3.5] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbqN7BceSRhS",
   "metadata": {
    "id": "dbqN7BceSRhS"
   },
   "source": [
    "### [3.5.1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caLTQ8EtSRhT",
   "metadata": {
    "id": "caLTQ8EtSRhT",
    "outputId": "0b11a805-1a59-4cce-939d-37f21520c610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8030672708260718\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_all_non_arabic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rad8wPeSSRhU",
   "metadata": {
    "id": "rad8wPeSSRhU"
   },
   "source": [
    "### [3.5.2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UZuYtSHaSRhU",
   "metadata": {
    "id": "UZuYtSHaSRhU",
    "outputId": "fae164d4-98b7-402c-b4bb-875def9b3c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8057103064066853\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_punctuation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FbIUIkezSRhU",
   "metadata": {
    "id": "FbIUIkezSRhU"
   },
   "source": [
    "### [3.5.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otquvQjuSRhV",
   "metadata": {
    "id": "otquvQjuSRhV",
    "outputId": "70a2f84f-fab1-4db7-de18-665b545ae664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8082144100243648\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N4WDktTgRNZf",
   "metadata": {
    "id": "N4WDktTgRNZf"
   },
   "source": [
    "## [3.6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B6icsYsFRNZf",
   "metadata": {
    "id": "B6icsYsFRNZf",
    "outputId": "6753ca57-070b-4463-df2d-0e6cd18e9c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8006273963053329\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\",\"remove_stop_words\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wbGPWNtoR4p-",
   "metadata": {
    "id": "wbGPWNtoR4p-"
   },
   "source": [
    "## [3.7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fAiyofe3R4qA",
   "metadata": {
    "id": "fAiyofe3R4qA",
    "outputId": "c3e11c36-b754-4081-8c59-cc2af3490704"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7936563262460787\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\",\"lemmatization\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V-rCzzoMR41T",
   "metadata": {
    "id": "V-rCzzoMR41T"
   },
   "source": [
    "## [3.8] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iXF2L4Z-Sd3N",
   "metadata": {
    "id": "iXF2L4Z-Sd3N"
   },
   "source": [
    "### [3.8.1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wk-Z3Gw4Sd3O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wk-Z3Gw4Sd3O",
    "outputId": "aff3187f-db1e-4bf9-a35a-716a13ba30c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078663418029934"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\",\"uniform_hamza\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ij5gdJA4Sd3O",
   "metadata": {
    "id": "ij5gdJA4Sd3O"
   },
   "source": [
    "### [3.8.2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bDLOsd4tSd3O",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDLOsd4tSd3O",
    "outputId": "d8eb88cb-75f8-460f-db8b-d1ad97285677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8033414549251653"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\",\"uniform_alef\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H6k8JnJDSd3P",
   "metadata": {
    "id": "H6k8JnJDSd3P"
   },
   "source": [
    "### [3.8.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JhSOCYLmSd3P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhSOCYLmSd3P",
    "outputId": "60c9f077-3484-4e0b-a36c-414151ff01b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091922005571031"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\",\"tatweel\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1TmDb343Sls9",
   "metadata": {
    "id": "1TmDb343Sls9"
   },
   "source": [
    "### [3.8.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wWJ-Z11_Sls-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wWJ-Z11_Sls-",
    "outputId": "8849a502-dd23-40d5-dbc3-4f4432d172c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8102367688022284"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\",\"tatweel\",\"tashkil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0V5LD9EWVgY7",
   "metadata": {
    "id": "0V5LD9EWVgY7"
   },
   "source": [
    "## [3.9] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-4gINe2sfCoW",
   "metadata": {
    "id": "-4gINe2sfCoW"
   },
   "source": [
    "<font size=\"4\">\n",
    "نلاحظ أن حذف الفراغات أنقص الدقة والأسباب مجهولة\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AkVzG3AWVgZA",
   "metadata": {
    "id": "AkVzG3AWVgZA",
    "outputId": "5dabe7e2-c85d-4c62-c1cb-0acf709a7687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8084958217270195\n"
     ]
    }
   ],
   "source": [
    "classify_on_cleaned_data([\"replace_nums\",\"remove_emojies\",\"tatweel\",\"tashkil\",\"remove_space\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vc96CuQStFA9",
   "metadata": {
    "id": "vc96CuQStFA9"
   },
   "source": [
    "## [3.10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pCJ7itd3tJjw",
   "metadata": {
    "id": "pCJ7itd3tJjw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lSaKeo_BEuWK",
   "metadata": {
    "id": "lSaKeo_BEuWK"
   },
   "source": [
    "## Print Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A_3K2Wz9EuWK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "A_3K2Wz9EuWK",
    "outputId": "f382a09e-4322-4923-e7a0-93964a9507b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_step_number</th>\n",
       "      <th>preprocessing_methods</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.1</td>\n",
       "      <td>remove_url + remove_mentions</td>\n",
       "      <td>0.804461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2</td>\n",
       "      <td>remove_hashtags</td>\n",
       "      <td>0.801811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>remove_repeated</td>\n",
       "      <td>0.805430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.4.1</td>\n",
       "      <td>uniform_nums</td>\n",
       "      <td>0.806474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.4.2</td>\n",
       "      <td>replace_nums</td>\n",
       "      <td>0.808562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.4.3</td>\n",
       "      <td>remove_nums</td>\n",
       "      <td>0.805082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5.1</td>\n",
       "      <td>replace_nums + remove_all_non_arabic</td>\n",
       "      <td>0.803067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.5.2</td>\n",
       "      <td>replace_nums + remove_punctuation</td>\n",
       "      <td>0.805710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.5.3</td>\n",
       "      <td>replace_nums + remove_emojies</td>\n",
       "      <td>0.808214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.6</td>\n",
       "      <td>replace_nums + remove_emojies + remove_stop_words</td>\n",
       "      <td>0.800627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.7</td>\n",
       "      <td>replace_nums + remove_emojies + lemmatization</td>\n",
       "      <td>0.793656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.8.1</td>\n",
       "      <td>replace_nums + remove_emojies + uniform_hamza</td>\n",
       "      <td>0.807866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.8.2</td>\n",
       "      <td>replace_nums + remove_emojies + uniform_alef</td>\n",
       "      <td>0.803341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.8.3</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel</td>\n",
       "      <td>0.809192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.8.4</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel + tashkil</td>\n",
       "      <td>0.810237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.9</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel + tash...</td>\n",
       "      <td>0.808496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_step_number                              preprocessing_methods  \\\n",
       "0                   3.1                       remove_url + remove_mentions   \n",
       "1                   3.2                                    remove_hashtags   \n",
       "2                   3.3                                    remove_repeated   \n",
       "3                 3.4.1                                       uniform_nums   \n",
       "4                 3.4.2                                       replace_nums   \n",
       "5                 3.4.3                                        remove_nums   \n",
       "6                 3.5.1               replace_nums + remove_all_non_arabic   \n",
       "7                 3.5.2                  replace_nums + remove_punctuation   \n",
       "8                 3.5.3                      replace_nums + remove_emojies   \n",
       "9                   3.6  replace_nums + remove_emojies + remove_stop_words   \n",
       "10                  3.7      replace_nums + remove_emojies + lemmatization   \n",
       "11                3.8.1      replace_nums + remove_emojies + uniform_hamza   \n",
       "12                3.8.2       replace_nums + remove_emojies + uniform_alef   \n",
       "13                3.8.3            replace_nums + remove_emojies + tatweel   \n",
       "14                3.8.4  replace_nums + remove_emojies + tatweel + tashkil   \n",
       "15                  3.9  replace_nums + remove_emojies + tatweel + tash...   \n",
       "\n",
       "    accuracy  \n",
       "0   0.804461  \n",
       "1   0.801811  \n",
       "2   0.805430  \n",
       "3   0.806474  \n",
       "4   0.808562  \n",
       "5   0.805082  \n",
       "6   0.803067  \n",
       "7   0.805710  \n",
       "8   0.808214  \n",
       "9   0.800627  \n",
       "10  0.793656  \n",
       "11  0.807866  \n",
       "12  0.803341  \n",
       "13  0.809192  \n",
       "14  0.810237  \n",
       "15  0.808496  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(bag_logistic_comparison_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5egzCqh_Dvrf",
   "metadata": {
    "id": "5egzCqh_Dvrf"
   },
   "source": [
    "## Your best model\n",
    "إن أفضل العمليات هي حذف استبدال الأرقام بنجمة وحذف الايموجيز وحذف التشكيل والتطويل "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06640e5",
   "metadata": {
    "id": "d06640e5"
   },
   "outputs": [],
   "source": [
    "clean = [\"replace_nums\",\"remove_emojies\",\"tatweel\",\"tashkil\"]\n",
    "train = train_data_01.copy()\n",
    "test = test_data_01.copy()\n",
    "train[\"cleaned\"] =train.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "test[\"cleaned\"] =test.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "\n",
    "train = drop_duplicate_empty_for_clean_data(train)\n",
    "test = drop_duplicate_empty_for_clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C8LAew5pDvrg",
   "metadata": {
    "id": "C8LAew5pDvrg",
    "outputId": "c0e7c2d3-899b-4b60-c9f6-ba3b343859da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8084449021627188\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression(max_iter =  200)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train.cleaned)\n",
    "X_test = vectorizer.transform(test.cleaned)\n",
    "\n",
    "# test your model\n",
    "classifier.fit(X_train, train.label_num)\n",
    "accuracy = classifier.score(X_test, test.label_num)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "Zso2cwozEex7",
   "metadata": {
    "id": "Zso2cwozEex7"
   },
   "outputs": [],
   "source": [
    "model_comparison_table['question_step_number'].append(\"3\")\n",
    "model_comparison_table['model_name'].append(\"logistic regression with bag of words\")\n",
    "model_comparison_table['parameters'].append(\"defualt\")\n",
    "model_comparison_table['preprocessing_methods'].append(\"replace_nums + remove_emojies + tatweel + tashkil\")\n",
    "model_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bPlfAwx7FfjJ",
   "metadata": {
    "id": "bPlfAwx7FfjJ"
   },
   "source": [
    "# Question [4]: TF-IDF with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AWU_I4CjFfjP",
   "metadata": {
    "id": "AWU_I4CjFfjP"
   },
   "source": [
    "Prapere The Comparison Dictionary for this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CxP9dtS-FfjQ",
   "metadata": {
    "id": "CxP9dtS-FfjQ"
   },
   "outputs": [],
   "source": [
    "tf_idf_comparison_table = {}\n",
    "\n",
    "tf_idf_comparison_table['question_step_number'] = []\n",
    "tf_idf_comparison_table['model_name'] = []\n",
    "tf_idf_comparison_table['parameters'] = []\n",
    "tf_idf_comparison_table['accuracy'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6147d",
   "metadata": {
    "id": "55e6147d"
   },
   "outputs": [],
   "source": [
    "def store_result_tf_idf(question_step_number,accuracy,model_name = \"logistic regression with TF_IDF\",\n",
    "                        parameters=\"default parameters\"):\n",
    "    tf_idf_comparison_table['question_step_number'].append(question_step_number)\n",
    "    tf_idf_comparison_table['model_name'].append(model_name)\n",
    "    tf_idf_comparison_table['parameters'].append(parameters)\n",
    "    tf_idf_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed533614",
   "metadata": {
    "id": "ed533614"
   },
   "outputs": [],
   "source": [
    "valid = valid_data_01.copy()\n",
    "valid[\"cleaned\"] =valid.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "valid = drop_duplicate_empty_for_clean_data(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df211c7b",
   "metadata": {
    "direction": "rtl",
    "id": "df211c7b"
   },
   "source": [
    "<font size=\"4\">\n",
    "يأخذ التابع data التدريب والاختبار(valid /test) حسب الطلب، وباراميترات الـTfidf ومتحول لمعرفة الdictionary الذي سيخزن به، التابع شبيه بما قام فيه التابع بالقسم الثاني ولكن هنا Tfidf بدلا من Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdbb110",
   "metadata": {
    "id": "1bdbb110"
   },
   "outputs": [],
   "source": [
    "def tfidf(test,train=train, min_df=1 ,max_df=1,ngram_range=(1, 2),store=\"valid\"):\n",
    " \n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df, max_df=max_df, ngram_range=ngram_range)\n",
    "    classifier = LogisticRegression(max_iter =  200)\n",
    "\n",
    "    X_train = tfidf_vectorizer.fit_transform(train.cleaned)\n",
    "    X_test = tfidf_vectorizer.transform(test.cleaned)\n",
    "\n",
    "    # test your model\n",
    "    classifier.fit(X_train, train.label_num)\n",
    "    accuracy = classifier.score(X_test, test.label_num)\n",
    "    parameters = f\"min_df={min_df} max_df={max_df} ngram={ngram_range}\"\n",
    "    if store == \"valid\":\n",
    "        store_result_tf_idf(question_step_number =\"4.1\",accuracy= accuracy,parameters = parameters)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wLfn2vfUFfjQ",
   "metadata": {
    "id": "wLfn2vfUFfjQ"
   },
   "source": [
    "## [4.1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wTANTEnOFfjQ",
   "metadata": {
    "id": "wTANTEnOFfjQ",
    "outputId": "2eaef0b4-7f27-4db0-9a1f-761e38b0c3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7653203342618384\n"
     ]
    }
   ],
   "source": [
    "tfidf(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69c45da",
   "metadata": {
    "id": "b69c45da"
   },
   "outputs": [],
   "source": [
    "# tfidf(clean = clean,test=test_data_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03e2ad",
   "metadata": {
    "id": "ea03e2ad"
   },
   "source": [
    "## [4.2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b7513c",
   "metadata": {
    "id": "68b7513c",
    "outputId": "b5bd6db3-52e5-462d-bcc0-5a5b1d484040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7802924791086351\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=2, max_df=0.5, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc5397",
   "metadata": {
    "id": "bcfc5397",
    "outputId": "c6f82bff-e6dc-43c6-9c5f-82cf7356a654"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5825208913649025\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.2, max_df=0.5, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00711d66",
   "metadata": {
    "id": "00711d66",
    "outputId": "44996ad3-886e-4cf1-c1ce-553272cd7a42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7733286908077994\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=3, max_df=0.5, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d22b16",
   "metadata": {
    "id": "e3d22b16",
    "outputId": "3f1841c9-9598-423d-e427-2690a42763a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5362116991643454\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.4, max_df=0.8, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be515dfd",
   "metadata": {
    "id": "be515dfd",
    "outputId": "bd26c44e-2898-4db9-dc05-b818a2f2252e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5898328690807799\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.3, max_df=0.8, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5db40",
   "metadata": {
    "id": "b1d5db40",
    "outputId": "2efaa88a-9565-4538-9574-a3a61838f933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7827298050139275\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=2, max_df=0.8, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d509f84",
   "metadata": {
    "id": "9d509f84",
    "outputId": "06f9d51c-e6a7-4117-a32b-bc293da4bce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6368384401114207\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.02, max_df=0.5, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80a9c9",
   "metadata": {
    "id": "4a80a9c9",
    "outputId": "4548373a-add2-4e9e-b05b-13f47a651220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5988857938718662\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.05, max_df=0.5, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9212a",
   "metadata": {
    "id": "e7b9212a",
    "outputId": "c8986c30-5f05-45ed-8ffa-1d66ce28c304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6002785515320335\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.08, max_df=0.8, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061fd7b1",
   "metadata": {
    "id": "061fd7b1",
    "outputId": "00ec455d-56e1-4493-e5dc-5f673f784531"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6511142061281338\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.015, max_df=0.5, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb53e2f",
   "metadata": {
    "id": "4eb53e2f",
    "outputId": "da9cac27-f23c-4972-eb4c-ed831a79c599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7614902506963789\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0.0005, max_df=0.5, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d871192",
   "metadata": {
    "id": "0d871192",
    "outputId": "44119d3e-885c-471f-89dc-c107290bf69e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7914345403899722\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0, max_df=0.5, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abaefc6",
   "metadata": {
    "id": "4abaefc6",
    "outputId": "3840abdc-132a-442d-a1d8-6cfefb3586bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7907381615598886\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0, max_df=0.4, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02dc685",
   "metadata": {
    "id": "d02dc685",
    "outputId": "64a7aa04-7c8e-490c-f0da-d11584915ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7903899721448467\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0, max_df=0.7, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f90bb",
   "metadata": {
    "id": "114f90bb",
    "outputId": "3fb23adf-84fa-4994-a53d-7b3d95b7bbee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7914345403899722\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0, max_df=0.55, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c373952",
   "metadata": {
    "id": "9c373952",
    "outputId": "bf40b802-e4ab-42e7-c314-ea7c4a19d1be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7910863509749304\n"
     ]
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0, max_df=0.5, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6adedb",
   "metadata": {
    "id": "1b6adedb",
    "outputId": "a88385a3-84eb-4d29-b796-6cedc5bc2fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7896935933147632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7896935933147632"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(test=valid,min_df=0, max_df=0.5, ngram_range=(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5a969",
   "metadata": {
    "id": "e0b5a969"
   },
   "outputs": [],
   "source": [
    "tfidf(test=valid,min_df=0, max_df=0.5, ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fDl29bpGSMT",
   "metadata": {
    "id": "9fDl29bpGSMT"
   },
   "source": [
    "## [4.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rR_tP1OzGSMc",
   "metadata": {
    "id": "rR_tP1OzGSMc"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train.cleaned)\n",
    "X_valid = vectorizer.transform(valid.cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98f9c5",
   "metadata": {
    "id": "bf98f9c5"
   },
   "outputs": [],
   "source": [
    "def classify(classifier):\n",
    "  classifier.fit(X_train, train.label_num)\n",
    "  accuracy = classifier.score(X_valid, valid.label_num)\n",
    "  print(\"Accuracy:\", accuracy)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f4b3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d0f4b3f",
    "outputId": "f5db4a19-57ad-42e1-bd90-c843335e800a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5698697641675466\n"
     ]
    }
   ],
   "source": [
    "accuracy = classify( SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8234e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71e8234e",
    "outputId": "8835e965-f22b-47f9-aeb4-6024c826a753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5181274199225625\n"
     ]
    }
   ],
   "source": [
    "accuracy = classify(SVC(kernel =\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be87c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25be87c4",
    "outputId": "820212ce-1e4d-4317-aae6-f12970017fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5698697641675466\n"
     ]
    }
   ],
   "source": [
    "accuracy = classify( SVC(degree = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360a397",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f360a397",
    "outputId": "1b1bbf4f-98a4-48e1-cd8d-ded018c9eba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.518479408658923\n"
     ]
    }
   ],
   "source": [
    "accuracy = classify(SVC(kernel =\"poly\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z0kgCTUgok6P",
   "metadata": {
    "id": "z0kgCTUgok6P"
   },
   "source": [
    "<font size=\"4\">\n",
    "نلاحظ أنها لم تعطي نتائج جيدة\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B1Arms4fGh61",
   "metadata": {
    "id": "B1Arms4fGh61"
   },
   "source": [
    "## Print Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rG-ISTabGh62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "rG-ISTabGh62",
    "outputId": "988abfc2-3029-47ab-f4ba-3ddc75b40151"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_step_number</th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=1 max_df=1 ngram=(1, 2)</td>\n",
       "      <td>0.765320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=2 max_df=0.5 ngram=(1, 2)</td>\n",
       "      <td>0.780292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.2 max_df=0.5 ngram=(1, 2)</td>\n",
       "      <td>0.582521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=3 max_df=0.5 ngram=(1, 2)</td>\n",
       "      <td>0.773329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.4 max_df=0.8 ngram=(1, 2)</td>\n",
       "      <td>0.536212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.3 max_df=0.8 ngram=(1, 3)</td>\n",
       "      <td>0.589833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=2 max_df=0.8 ngram=(1, 3)</td>\n",
       "      <td>0.782730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.02 max_df=0.5 ngram=(1, 3)</td>\n",
       "      <td>0.636838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.05 max_df=0.5 ngram=(1, 3)</td>\n",
       "      <td>0.598886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.08 max_df=0.8 ngram=(1, 3)</td>\n",
       "      <td>0.600279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.015 max_df=0.5 ngram=(1, 3)</td>\n",
       "      <td>0.651114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0.0005 max_df=0.5 ngram=(1, 3)</td>\n",
       "      <td>0.761490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0 max_df=0.5 ngram=(1, 3)</td>\n",
       "      <td>0.791435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0 max_df=0.4 ngram=(1, 3)</td>\n",
       "      <td>0.790738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0 max_df=0.7 ngram=(1, 3)</td>\n",
       "      <td>0.790390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0 max_df=0.55 ngram=(1, 3)</td>\n",
       "      <td>0.791435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.1</td>\n",
       "      <td>logistic regression with TF_IDF</td>\n",
       "      <td>min_df=0 max_df=0.5 ngram=(1, 2)</td>\n",
       "      <td>0.791086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_step_number                       model_name  \\\n",
       "0                   4.1  logistic regression with TF_IDF   \n",
       "1                   4.1  logistic regression with TF_IDF   \n",
       "2                   4.1  logistic regression with TF_IDF   \n",
       "3                   4.1  logistic regression with TF_IDF   \n",
       "4                   4.1  logistic regression with TF_IDF   \n",
       "5                   4.1  logistic regression with TF_IDF   \n",
       "6                   4.1  logistic regression with TF_IDF   \n",
       "7                   4.1  logistic regression with TF_IDF   \n",
       "8                   4.1  logistic regression with TF_IDF   \n",
       "9                   4.1  logistic regression with TF_IDF   \n",
       "10                  4.1  logistic regression with TF_IDF   \n",
       "11                  4.1  logistic regression with TF_IDF   \n",
       "12                  4.1  logistic regression with TF_IDF   \n",
       "13                  4.1  logistic regression with TF_IDF   \n",
       "14                  4.1  logistic regression with TF_IDF   \n",
       "15                  4.1  logistic regression with TF_IDF   \n",
       "16                  4.1  logistic regression with TF_IDF   \n",
       "\n",
       "                               parameters  accuracy  \n",
       "0          min_df=1 max_df=1 ngram=(1, 2)  0.765320  \n",
       "1        min_df=2 max_df=0.5 ngram=(1, 2)  0.780292  \n",
       "2      min_df=0.2 max_df=0.5 ngram=(1, 2)  0.582521  \n",
       "3        min_df=3 max_df=0.5 ngram=(1, 2)  0.773329  \n",
       "4      min_df=0.4 max_df=0.8 ngram=(1, 2)  0.536212  \n",
       "5      min_df=0.3 max_df=0.8 ngram=(1, 3)  0.589833  \n",
       "6        min_df=2 max_df=0.8 ngram=(1, 3)  0.782730  \n",
       "7     min_df=0.02 max_df=0.5 ngram=(1, 3)  0.636838  \n",
       "8     min_df=0.05 max_df=0.5 ngram=(1, 3)  0.598886  \n",
       "9     min_df=0.08 max_df=0.8 ngram=(1, 3)  0.600279  \n",
       "10   min_df=0.015 max_df=0.5 ngram=(1, 3)  0.651114  \n",
       "11  min_df=0.0005 max_df=0.5 ngram=(1, 3)  0.761490  \n",
       "12       min_df=0 max_df=0.5 ngram=(1, 3)  0.791435  \n",
       "13       min_df=0 max_df=0.4 ngram=(1, 3)  0.790738  \n",
       "14       min_df=0 max_df=0.7 ngram=(1, 3)  0.790390  \n",
       "15      min_df=0 max_df=0.55 ngram=(1, 3)  0.791435  \n",
       "16       min_df=0 max_df=0.5 ngram=(1, 2)  0.791086  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tf_idf_comparison_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78_CjYZCGh63",
   "metadata": {
    "id": "78_CjYZCGh63"
   },
   "source": [
    "## Your best model\n",
    "ما هو النموذج الأفضل؟ اكتبه هنا"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I5vU6JrJGh63",
   "metadata": {
    "id": "I5vU6JrJGh63",
    "outputId": "5ecaee9d-defb-400d-d200-ca3490b6dcb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8039821489872984\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "min_df=0\n",
    "max_df=0.5\n",
    "ngram_range=(1, 3)\n",
    "accuracy=tfidf(test=test,min_df=min_df, max_df=max_df, ngram_range=ngram_range,store=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "BVdVtInOGh63",
   "metadata": {
    "id": "BVdVtInOGh63"
   },
   "outputs": [],
   "source": [
    "\n",
    "parameters = f\"min_df={min_df} max_df={max_df} ngram={ngram_range}\"\n",
    "\n",
    "model_comparison_table['question_step_number'].append(\"4\")\n",
    "model_comparison_table['model_name'].append(\"logistic regression with tf-idf\")\n",
    "model_comparison_table['parameters'].append(parameters)\n",
    "model_comparison_table['preprocessing_methods'].append(\" + \".join(clean))\n",
    "model_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PX_GDsJYHOmO",
   "metadata": {
    "id": "PX_GDsJYHOmO"
   },
   "source": [
    "# Question [5]: Deep NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aIWfX3nkHOmW",
   "metadata": {
    "id": "aIWfX3nkHOmW"
   },
   "source": [
    "Prapere The Comparison Dictionary for this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drR1YXa8HOmX",
   "metadata": {
    "id": "drR1YXa8HOmX"
   },
   "outputs": [],
   "source": [
    "dnn_comparison_table = {}\n",
    "\n",
    "dnn_comparison_table['question_step_number'] = []\n",
    "dnn_comparison_table['model_name'] = []\n",
    "dnn_comparison_table['parameters'] = []\n",
    "dnn_comparison_table['accuracy'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nyeT0eFHOmX",
   "metadata": {
    "id": "0nyeT0eFHOmX"
   },
   "source": [
    "## [5.1] \n",
    "شرح ما يقوم به الكود\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "633b630b",
   "metadata": {
    "id": "633b630b"
   },
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "# clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "786313be",
   "metadata": {
    "id": "786313be"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(train.cleaned).toarray()\n",
    "X_valid = vectorizer.transform(valid.cleaned).toarray()\n",
    "X_test = vectorizer.transform(test.cleaned).toarray()\n",
    "\n",
    "y_train = train.label_num.values\n",
    "y_valid = valid.label_num.values\n",
    "y_test = test.label_num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iknvo4OVHOmX",
   "metadata": {
    "id": "iknvo4OVHOmX",
    "outputId": "fcc0e884-3678-45b9-ca32-aaa3d5bc0384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Training Accuracy: 0.9994\n",
      "Testing Accuracy:  0.7872\n"
     ]
    }
   ],
   "source": [
    "# do code\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                     epochs=100,\n",
    "                     verbose=False,\n",
    "#                      validation_split=0.2,\n",
    "#                     validation_data = (X_valid,y_valid),\n",
    "                     batch_size=10)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train,y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test,y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qZTkVP4nQJJ3",
   "metadata": {
    "id": "qZTkVP4nQJJ3"
   },
   "outputs": [],
   "source": [
    "dnn_comparison_table['question_step_number'].append(\"5.1\")\n",
    "dnn_comparison_table['model_name'].append(\"Fully Connected DNN\")\n",
    "dnn_comparison_table['parameters'].append(\"loss='binary_crossentropy', optimizer='adam', Dense neurons = 10\")\n",
    "dnn_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qhEvMB6BQEz2",
   "metadata": {
    "id": "qhEvMB6BQEz2"
   },
   "source": [
    "## [5.2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f13cc",
   "metadata": {
    "id": "043f13cc"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train.cleaned)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train.cleaned)\n",
    "X_test = tokenizer.texts_to_sequences(test.cleaned)\n",
    "X_valid = tokenizer.texts_to_sequences(valid.cleaned)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "\n",
    "maxlen = 150\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "X_valid = pad_sequences(X_valid, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3d8e61",
   "metadata": {
    "id": "5e3d8e61"
   },
   "outputs": [],
   "source": [
    "# do code\n",
    "embedding_dim = 50\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                     epochs=100,\n",
    "                     verbose=False,\n",
    "#                      validation_split=0.2,\n",
    "                    validation_data = (X_valid,y_valid),\n",
    "                     batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3acf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38e3acf1",
    "outputId": "7b3f7657-39a5-4500-e480-3323dedf4eb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9985\n",
      "Testing Accuracy:  0.7652\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train,y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test,y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VuZtja6bsFSn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuZtja6bsFSn",
    "outputId": "021227d0-c394-4b4d-a768-547b913040f6"
   },
   "outputs": [
    {

     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x7f81fb6083a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/weakref.py\", line 345, in remove\n",
      "    def remove(k, selfref=ref(self)):\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "# do code\n",
    "embedding_dim = 50\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                     epochs=100,\n",
    "                     verbose=False,\n",
    "#                      validation_split=0.2,\n",
    "                    validation_data = (X_valid,y_valid),\n",
    "                     batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lAZZU2ORoIqZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAZZU2ORoIqZ",
    "outputId": "087011fa-e813-4722-83e3-6ce18e0b7b2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5135\n",
      "Testing Accuracy:  0.5125\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train,y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test,y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-7n-VXiWLP2W",
   "metadata": {
    "id": "-7n-VXiWLP2W"
   },
   "outputs": [],
   "source": [
    "dnn_comparison_table['question_step_number'].append(\"5.2\")\n",
    "dnn_comparison_table['model_name'].append(\"Fully Connected DNN with Dropout\")\n",
    "dnn_comparison_table['parameters'].append(\"loss='binary_crossentropy', optimizer='adam', Dense neurons = 10\")\n",
    "dnn_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aVrfE8nQHOmY",
   "metadata": {
    "id": "aVrfE8nQHOmY"
   },
   "source": [
    "### Your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nc29YBVzHOmZ",
   "metadata": {
    "id": "nc29YBVzHOmZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "Ava6bB9OHOmZ",
   "metadata": {
    "id": "Ava6bB9OHOmZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_comparison_table['question_step_number'].append(\"5.2\")\n",
    "model_comparison_table['model_name'].append(\"Fully Connected DNN\")\n",
    "model_comparison_table['parameters'].append(\"loss='binary_crossentropy', optimizer='adam', Dense neurons = 10, embedding layer\")\n",
    "model_comparison_table['preprocessing_methods'].append(\" + \".join(clean))\n",
    "model_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Me9TPp8PHOmY",
   "metadata": {
    "id": "Me9TPp8PHOmY"
   },
   "source": [
    "## [5.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AcAcfSrFHOmY",
   "metadata": {
    "id": "AcAcfSrFHOmY"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a43df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d92a43df",
    "outputId": "3b303767-17d2-4b8b-e204-b4e4f0d96f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9294\n",
      "Testing Accuracy:  0.7583\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                    validation_data = (X_valid,y_valid),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f49cf",
   "metadata": {
    "id": "8d1f49cf"
   },
   "outputs": [],
   "source": [
    "dnn_comparison_table['question_step_number'].append(\"5.3\")\n",
    "dnn_comparison_table['model_name'].append(\"CNN\")\n",
    "dnn_comparison_table['parameters'].append(\"loss='binary_crossentropy', optimizer='adam', 1 Conv with 128 filters with size 5*5\")\n",
    "dnn_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hJhNHYYXI88y",
   "metadata": {
    "id": "hJhNHYYXI88y"
   },
   "source": [
    "## [5.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u6VtvSDoI885",
   "metadata": {
    "id": "u6VtvSDoI885"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "\n",
    "model.add(layers.LSTM(64, return_sequences=False,  dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_2dWoAXxj78S",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_2dWoAXxj78S",
    "outputId": "2b0cc321-c230-43f7-da91-6d396ab1e83b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5135\n",
      "Testing Accuracy:  0.5125\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=False,\n",
    "                     validation_data = (X_valid,y_valid),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TczR4aGwMBPM",
   "metadata": {
    "id": "TczR4aGwMBPM"
   },
   "outputs": [],
   "source": [
    "dnn_comparison_table['question_step_number'].append(\"5.4\")\n",
    "dnn_comparison_table['model_name'].append(\"LSTM\")\n",
    "dnn_comparison_table['parameters'].append(\"loss='binary_crossentropy', optimizer='adam', Lstm neurons = 64\")\n",
    "dnn_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5N0vwmpMKQCs",
   "metadata": {
    "id": "5N0vwmpMKQCs"
   },
   "source": [
    "### Your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda4f02",
   "metadata": {
    "id": "0NY3HdSvKQCw"
   },
   "outputs": [],
   "source": [
    "# test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ZhmsKwtOKQCw",
   "metadata": {
    "id": "ZhmsKwtOKQCw"
   },
   "outputs": [],
   "source": [
    "model_comparison_table['question_step_number'].append(\"5.4\")\n",
    "model_comparison_table['model_name'].append(\"LSTM\")\n",
    "model_comparison_table['parameters'].append(\"loss='binary_crossentropy', optimizer='adam', Lstm neurons = 64\")\n",
    "model_comparison_table['preprocessing_methods'].append(\" + \".join(clean))\n",
    "model_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3TZ6p2uJI9Ou",
   "metadata": {
    "id": "3TZ6p2uJI9Ou"
   },
   "source": [
    "## [5.5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kztqizjhI9Ou",
   "metadata": {
    "id": "kztqizjhI9Ou"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "oRrvmFgEHOmY",
   "metadata": {
    "id": "oRrvmFgEHOmY"
   },
   "source": [
    "## Print Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XIejVm96HOmY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "XIejVm96HOmY",
    "outputId": "5af6f4cc-ee6f-41d7-ccdc-825fc8720d0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fb5722c2-2bbd-480e-9a77-b98fe94765c0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_step_number</th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>Fully Connected DNN</td>\n",
       "      <td>loss='binary_crossentropy', optimizer='adam', ...</td>\n",
       "      <td>0.7872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>Fully Connected DNN with Dropout</td>\n",
       "      <td>loss='binary_crossentropy', optimizer='adam', ...</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.4</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>loss='binary_crossentropy', optimizer='adam', ...</td>\n",
       "      <td>0.5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>CNN</td>\n",
       "      <td>loss='binary_crossentropy', optimizer='adam', ...</td>\n",
       "      <td>0.7583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb5722c2-2bbd-480e-9a77-b98fe94765c0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fb5722c2-2bbd-480e-9a77-b98fe94765c0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fb5722c2-2bbd-480e-9a77-b98fe94765c0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  question_step_number                        model_name  \\\n",
       "0                  5.1               Fully Connected DNN   \n",
       "1                  5.2  Fully Connected DNN with Dropout   \n",
       "2                  5.4                              LSTM   \n",
       "3                  5.3                               CNN   \n",
       "\n",
       "                                          parameters  accuracy  \n",
       "0  loss='binary_crossentropy', optimizer='adam', ...    0.7872  \n",
       "1  loss='binary_crossentropy', optimizer='adam', ...    0.5125  \n",
       "2  loss='binary_crossentropy', optimizer='adam', ...    0.5125  \n",
       "3  loss='binary_crossentropy', optimizer='adam', ...    0.7583  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(dnn_comparison_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cPd2f_LZKy6U",
   "metadata": {
    "id": "cPd2f_LZKy6U"
   },
   "source": [
    "# Question [6]: Train on all Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OWcnexI2Ky6V",
   "metadata": {
    "id": "OWcnexI2Ky6V"
   },
   "source": [
    "## [6.1] \n",
    "شرح ما يقوم به الكود\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ztx_to6MfPu_",
   "metadata": {
    "id": "ztx_to6MfPu_"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels.\n",
    "def encoding(data): \n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    # Encode labels in column 'Country'. \n",
    "    data[\"label\"]= label_encoder.fit_transform(data[\"label\"]) \n",
    "    print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "KgPoxtj_aXZt",
   "metadata": {
    "id": "KgPoxtj_aXZt"
   },
   "outputs": [],
   "source": [
    "def convert_to_num(l):\n",
    "  if l== labels[0]:\n",
    "    return 0\n",
    "  elif l== labels[1]:\n",
    "    return 1\n",
    "  elif l== labels[2]:\n",
    "    return 2\n",
    "  else:\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "phpNYySdKy6V",
   "metadata": {
    "id": "phpNYySdKy6V"
   },
   "outputs": [],
   "source": [
    "# do code\n",
    "clean = [\"replace_nums\",\"remove_emojies\",\"tatweel\",\"tashkil\"]\n",
    "\n",
    "train_data[\"label\"] = train_data.label.apply(convert_to_num)\n",
    "# valid_data[\"label_num\"] = valid_data.label.apply(convert_to_num)\n",
    "test_data[\"label\"] = test_data.label.apply(convert_to_num)\n",
    "# train_data = encoding(train_data)\n",
    "# valid_data = encoding(valid_data)\n",
    "# test_data = encoding(test_data)\n",
    "\n",
    "train_data[\"text\"] =train_data.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "test_data[\"text\"] =test_data.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "# valid_data[\"cleaned\"] =valid_data.text.apply(lambda tweet: preprocess(tweet, clean))\n",
    "\n",
    "train_data = drop_duplicate_empty_for_clean_data(train_data,c=\"text\")\n",
    "# valid_data = drop_duplicate_empty_for_clean_data(valid_data)\n",
    "test_data = drop_duplicate_empty_for_clean_data(test_data,c=\"text\")\n",
    "    \n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_data.text)\n",
    "# X_valid = vectorizer.transform(valid_data.cleaned).toarray()\n",
    "X_test = vectorizer.transform(test_data.text)\n",
    "\n",
    "y_train = train_data.label.values\n",
    "# y_valid = valid.label_num.values\n",
    "y_test = test_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ZiFx8hlndpzU",
   "metadata": {
    "id": "ZiFx8hlndpzU"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data.text)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data.text)\n",
    "X_test = tokenizer.texts_to_sequences(test_data.text)\n",
    "# X_valid = tokenizer.texts_to_sequences(valid.cleaned)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "\n",
    "maxlen = 150\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "# X_valid = pad_sequences(X_valid, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4_zI7O7fcEfc",
   "metadata": {
    "id": "4_zI7O7fcEfc"
   },
   "outputs": [],
   "source": [
    "# do code\n",
    "embedding_dim = 50\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss=losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "                     epochs=100,\n",
    "                     verbose=False,\n",
    "                     validation_split=0.2,\n",
    "                    # validation_data = (X_valid,y_valid),\n",
    "                     batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "T74z2XthlDhC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T74z2XthlDhC",
    "outputId": "0a338cad-0d9d-448e-ceb5-c901c35fc36a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8796\n",
      "Testing Accuracy:  0.5920\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "Cc1nQET3Ky6V",
   "metadata": {
    "id": "Cc1nQET3Ky6V"
   },
   "outputs": [],
   "source": [
    "model_comparison_table['question_step_number'].append(\"6.1\")\n",
    "model_comparison_table['model_name'].append(\"DNNwith all classes\")\n",
    "model_comparison_table['parameters'].append(\"loss='spase_categorical_crossentropy', optimizer='adam' ,Dense with 10 neorons ,embedding layer\")\n",
    "model_comparison_table['preprocessing_methods'].append(\" + \".join(clean))\n",
    "model_comparison_table['accuracy'].append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XMcsisekLAbf",
   "metadata": {
    "id": "XMcsisekLAbf"
   },
   "source": [
    "## [6.2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fj5im0rLAbh",
   "metadata": {
    "id": "7fj5im0rLAbh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Ia98LzHjLSTT",
   "metadata": {
    "id": "Ia98LzHjLSTT"
   },
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "YPXXhSPILSTU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "YPXXhSPILSTU",
    "outputId": "43741570-3aa1-4f3b-c090-7cb1dc6e9e86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a055f60e-6f1d-4bc3-a33d-0aff6ce41fbd\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_step_number</th>\n",
       "      <th>model_name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>preprocessing_methods</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>baseline logistic regression with bag of words</td>\n",
       "      <td>default</td>\n",
       "      <td>none</td>\n",
       "      <td>0.806474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>logistic regression with bag of words</td>\n",
       "      <td>defualt</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel + tashkil</td>\n",
       "      <td>0.808445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>logistic regression with tf-idf</td>\n",
       "      <td>min_df=0 max_df=0.5 ngram=(1, 3)</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel + tashkil</td>\n",
       "      <td>0.803982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.2</td>\n",
       "      <td>Fully Connected DNN</td>\n",
       "      <td>loss='binary_crossentropy', optimizer='adam', ...</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel + tashkil</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>loss='binary_crossentropy', optimizer='adam', ...</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel + tashkil</td>\n",
       "      <td>0.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.1</td>\n",
       "      <td>DNNwith all classes</td>\n",
       "      <td>loss='spase_categorical_crossentropy', optimiz...</td>\n",
       "      <td>replace_nums + remove_emojies + tatweel + tashkil</td>\n",
       "      <td>0.592046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a055f60e-6f1d-4bc3-a33d-0aff6ce41fbd')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a055f60e-6f1d-4bc3-a33d-0aff6ce41fbd button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a055f60e-6f1d-4bc3-a33d-0aff6ce41fbd');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  question_step_number                                      model_name  \\\n",
       "0                    2  baseline logistic regression with bag of words   \n",
       "1                    3           logistic regression with bag of words   \n",
       "2                    4                 logistic regression with tf-idf   \n",
       "3                  5.2                             Fully Connected DNN   \n",
       "4                  5.4                                            LSTM   \n",
       "5                  6.1                             DNNwith all classes   \n",
       "\n",
       "                                          parameters  \\\n",
       "0                                            default   \n",
       "1                                            defualt   \n",
       "2                   min_df=0 max_df=0.5 ngram=(1, 3)   \n",
       "3  loss='binary_crossentropy', optimizer='adam', ...   \n",
       "4  loss='binary_crossentropy', optimizer='adam', ...   \n",
       "5  loss='spase_categorical_crossentropy', optimiz...   \n",
       "\n",
       "                               preprocessing_methods  accuracy  \n",
       "0                                               none  0.806474  \n",
       "1  replace_nums + remove_emojies + tatweel + tashkil  0.808445  \n",
       "2  replace_nums + remove_emojies + tatweel + tashkil  0.803982  \n",
       "3  replace_nums + remove_emojies + tatweel + tashkil  0.512500  \n",
       "4  replace_nums + remove_emojies + tatweel + tashkil  0.512500  \n",
       "5  replace_nums + remove_emojies + tatweel + tashkil  0.592046  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(model_comparison_table)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "tjn0G_5eLiSZ",
   "metadata": {
    "id": "tjn0G_5eLiSZ"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"سدره ميرخان.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62BrhBBvLtxr",
   "metadata": {
    "id": "62BrhBBvLtxr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "GY-HhD2YRNZe",
    "3fM_FPldSCxp",
    "N2z1KmQXSAFs",
    "fCBHc2y6SAL5",
    "P1aLjPbzRNZe",
    "dbqN7BceSRhS",
    "rad8wPeSSRhU",
    "FbIUIkezSRhU",
    "N4WDktTgRNZf",
    "wbGPWNtoR4p-",
    "vc96CuQStFA9"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
